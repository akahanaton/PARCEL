from snakemake.utils import R
from os.path import join
import csv

# simulate a bash login shell, see https://bitbucket.org/johanneskoester/snakemake/wiki/FAQ
shell.executable("/bin/bash")
#
# # "unofficial bash strict mode" http://www.redsymbol.net/articles/unofficial-bash-strict-mode/
shell.prefix("source ~/.bashrc; set -euo pipefail;")
#
#

# Globals ---------------------------------------------------------------------

# get the seqbatch : libid pairs for given comparebatch id
LIBIDS = []
SEQBATCHS = []
SEQDIR = []
SEQFILES = []
TREATMENTS = []
sampleinfo = open(config["SAMPLEINFO"],"r",newline='')
for line in sampleinfo:
	allelems = line.strip().split("\t");
	if allelems[6] == config["COMPAREBATCH"]:
		LIBIDS.append(allelems[1])
		SEQBATCHS.append(allelems[4])
		SEQDIR.append(allelems[8])
		SEQFILES.append(allelems[8] + allelems[7])
		if allelems[2] != config["CONTROL"]:
			TREATMENTS.append(allelems[2])

TREATMENTS = list(set(TREATMENTS))

#print(LIBIDS)
#print(SEQBATCHS)

# get condition and id pair
CONDITIONS = {}
sampleinfo = open(config["SAMPLEINFO"],"r",newline='')
for line in sampleinfo:
	CONDITIONS[line.split("\t")[1]] = line.split("\t")[2]


###################################################################################
# for calling differential sites
###################################################################################

OUTPUTDIRCOV = {
 "AUTOBATCH": {
    "T": "Batch",
    "F": "NoBatch"
 },
 "VSALL": {
    "T": "vsAll",
    "F": "onlyControl"
 },
}

RESULTDIR = config["PARCELDIR"] + config["COMPAREBATCH"] + "/"

#GENEDIFFPRE = config["PARCELDIR"] + "Gene_" + {wildcards.treatment}
#GENEDIFFDIR = GENEDIFFPRE + "_" + SUFFIX + "/"
#
#FILTERPRE = config["PARCELDIR"] + "Filter_" + {wildcards.treatment} + "_" + config["TOPCOV"] 
#FILTERDIR = FILTERPRE + "_" + SUFFIX + "_" + config["EVALUECUT"] + "_" + config["WFC"] + "/"


# define function to convert id to sample name


#getSampleInfo <- function(configfile,id,querykey) {
#	mydata = read.table(configfile,header=T,sep="\t");
#	result = mydata[mydata[,"LibID"]==id,querykey];
#	return(result);
#    # R code
#}
#
#

# snakemake -np  -s cutadaptor.sk --configfile conf-cutadaptor.json  --dag |  dot -Tsvg > dag.svg

def get_bedgraph_files(wc):
	return [config["BEDGRAPHDIR"] + config["COMPAREBATCH"] + "/" + CONDITIONS[LIBIDS[k]] + '_{}'.format(LIBIDS[k]) + '_{}_nor.bedgraph.gz'.format(SEQBATCHS[k]) for k in range(len(LIBIDS))]

rule final:
	input: 
		#config["COVDIR"] + config["COMPAREBATCH"] + "/" + "allcov.wide.min" + config["COVMIN"] + ".txt.gz",
		#config["COVDIR"] + config["COMPAREBATCH"] + "/" + "allgenecov.wide" + ".txt.gz",
		config["QUALCHECKDIR"] + config["COMPAREBATCH"] + "/" + "processingSummary.xls",
		config["COVDIR"] +config["COMPAREBATCH"] + "/" +  "allribocov.wide" + ".txt.gz",
		expand(config["PARCELDIR"] + config["COMPAREBATCH"] + "/" + "combined_{treatment}_output2_wfilters.txt",treatment = TREATMENTS),
		expand(config["PARCELDIR"] + config["COMPAREBATCH"] + "/" + "{treatment}_covplot/sigRegion.xls",treatment = TREATMENTS),
		#get_bedgraph_files
		
rule trimAdaptor:
	input: 
		config["INPUTDIR"] + "{seqbatch}/" + "{id}.fastq.gz"
		#get_input_files
	output: 
		trimseq = config["TRIMDIR"] + "{seqbatch}/" + "{id}.trim.fastq.gz",
		trimseqTemp = temp(config["TRIMDIR"] + "{seqbatch}/" + "{id}.trim.fastq"),
		trimlog = config["TRIMDIR"] + "{seqbatch}/" + "read.trim.{id}.log"
		#trimsum = config["TRIMDIR"] + "{seqbatch}/" + "read.trim.{id}.log.sum"
	params:
		adp1={config["ADAPTER"]["A"]}, adp2={config["ADAPTER"]["B"]}

	log: config["TRIMDIR"] + "{seqbatch}/" + "/read.trim.{id}.err"
	threads: 16
	shell:
		#ID={wildcards.id} perl {config[PARSE_CUT_ADT]} {output.trimlog} > {output.trimsum}
		"""
			{config[CUTADPT]} -a AP1={params.adp1} -g AP2={params.adp2} -n 2 -O 5 -y 'FOUND__{{name}}__' -m 20 -o {output.trimseqTemp} {input} > {output.trimlog} 
			pigz -c -p {threads} {output.trimseqTemp} > {output.trimseq}
		"""

rule parseAdpTrimLog:
	input:
		rules.trimAdaptor.output.trimlog
	output:
		trimsum = config["TRIMDIR"] + "{seqbatch}/" + "read.trim.{id}.log.sum"
	shell:
		"""
			ID={wildcards.id} perl {config[PARSE_CUT_ADT]} {input} > {output.trimsum}

		"""


rule collectAdpTrimLog:
	input:
		expand(config["TRIMDIR"] + "{seqbatch}/" + 'read.trim.{id}.log.sum', zip, id=LIBIDS, seqbatch=SEQBATCHS)
	output:
		config["TRIMDIR"] + config["COMPAREBATCH"] + "/" + "trimSummary.txt"
	shell:
		"""
			cat {input} > {output}
		"""

rule mapToGenome:
	input:
		rules.trimAdaptor.output.trimseq
	output:
		bamresult = config["MAPBAMS"] + "{seqbatch}/" + "{id}.trim.fastq.genome_mapping_best_sort.bam",
		bamindex = config["MAPBAMS"] + "{seqbatch}/" + "{id}.trim.fastq.genome_mapping_best_sort.bam.bai",
		maplog = config["MAPBAMS"] + "{seqbatch}/" + "{id}.trim.fastq.genome_mapping.log",
		logsum = config["MAPBAMS"] + "{seqbatch}/" + "{id}.trim.fastq.genome_mapping.summary"
		
	params:
		mismatch = config["MISMATCH"],
		seqbatch = lambda wildcards: wildcards.seqbatch,
		outdir = config["MAPBAMS"] + "{seqbatch}",
		mapmodel = config["MAPMODEL"],
		genome = config["REFGENOME"]
		#ID={wildcards.id} perl {config[SUM_MAPLOG]} {output.maplog} > {output.logsum}
	threads: 32
	shell:
		"""
			REPLACE=yes CPUNUM={threads} MISMATCH={params.mismatch} perl {config[MAP_WAPPER]} {input} {params.outdir} {params.mapmodel} {params.genome}
			ID={wildcards.id} perl {config[SUM_MAPLOG]} {output.maplog} > {output.logsum}
		"""
		#ID={wildcards.id} perl {config[SUM_MAPLOG]} {output.maplog} > {output.logsum}

#rule bedgraphTrack:
#	input:
#		bamresult = rules.mapToGenome.output.bamresult
#	output:
#		#config["BEDGRAPHDIR"] + CONDITIONS.get({id}) + '_{id}.bedgraph.gz'
#		#condition = lambda wildcards: CONDITIONS[wildcards.id]
#		#config["BEDGRAPHDIR"] + lamda wildcards: CONDITIONS[wildcards.id] + '_{id}.bedgraph.gz'
#		config["BEDGRAPHDIR"] + config["COMPAREBATCH"] + "/" + "{condition}_{id}_{seqbatch}_nor.bedgraph.gz"
#	params:
#		condition = lambda wildcards: CONDITIONS[wildcards.id]
#	shell:
#		"""
#			COVMIN=0 FIVEPOS=yes perl {config[TOBEDGRAPH]} {input.bamresult} {params.condition}_{wildcards.id}_nor {config[BEDGRAPH_SPE]} yes yes no | pigz -c -p 8 > {output}
#		"""

rule collectMapLog:
	input:
		expand(config["MAPBAMS"] + "{seqbatch}/" + '{id}.trim.fastq.genome_mapping.summary', zip, id=LIBIDS, seqbatch=SEQBATCHS)
	output:
		config["MAPBAMS"] + config["COMPAREBATCH"] + "/" + "mapSummary.txt"
	shell:
		"""
			cat {input} > {output}
		"""

rule coverageCount:
	input:
		bamresult = rules.mapToGenome.output.bamresult
	output:
		config["COVDIR"] + "{seqbatch}/" + "{id}.cov.txt.gz"
	threads: 4,
	params: numhit = config["NUMHIT"] 
	shell:
		"""
			NUMHIT={params.numhit} sh {config[BAMTOCOV]} {input.bamresult} {wildcards.id} {config[GENOMESIZE]} | pigz -p {threads} -c > {output} 
		"""

rule collectCovCount:
	input:
		expand(config["COVDIR"] + "{seqbatch}/" + "{id}.cov.txt.gz", zip, id=LIBIDS, seqbatch=SEQBATCHS)
	output:
		config["COVDIR"] + config["COMPAREBATCH"] + "/" + "allcov.txt.gz"
	threads: 8
	shell:
		"""
			zcat {input} | pigz -p {threads} -c > {output}
		"""

rule reshapeCovCount:
	input:
		rules.collectCovCount.output
	output:
		config["COVDIR"] + config["COMPAREBATCH"] + "/" + "allcov.wide.min" + config["COVMIN"] + ".txt.gz"
	params:
		splitby = config["SPLITBY"], sampleinfo = config["SAMPLEINFO"]
	threads: 1
	shell:
		"""
			Rscript {config[RESHAPETABLE]} -i {input} -o {output} -v V3 -f V1+V2~V4 --header F --filterbySum {config[COVMIN]} --splitBy {params.splitby} --sampleinfo {params.sampleinfo}
		"""

rule reshapeCovCountHigh:
	input:
		rules.collectCovCount.output
	output:
		config["COVDIR"] + config["COMPAREBATCH"] + "/" + "allcov.wide.min100" + ".txt.gz"
	threads: 1
	params: sampleinfo = config["SAMPLEINFO"], splitby = config["SPLITBY"]
	shell:
		"""
			Rscript {config[RESHAPETABLE]} -i {input} -o {output} -v V3 -f V1+V2~V4 --header F --filterbySum 100 --splitBy {params.splitby} --sampleinfo {params.sampleinfo}
		"""

rule coverageCountRibo:
	input:
		bamresult = rules.mapToGenome.output.bamresult
	output:
		config["COVDIR"] + "{seqbatch}/" + "{id}.ribocov.txt.gz"
	threads: 4 
	params: numhit = config["NUMHIT"] 
	shell:
		"""
			NUMHIT={params.numhit} sh {config[BAMTOGENECOUNT]} {input.bamresult} {config[RIBOEXONBED]} {wildcards.id} | pigz -p {threads} -c > {output} 
		"""

rule collectCovCountRibo:
	input:
		expand(config["COVDIR"] + "{seqbatch}/" + "{id}.ribocov.txt.gz", zip, id=LIBIDS, seqbatch=SEQBATCHS)
	output:
		config["COVDIR"] + config["COMPAREBATCH"] + "/" + "allribocov.txt.gz"
	threads: 8
	shell:
		"""
			zcat {input} | pigz -p {threads} -c > {output}
		"""

rule reshapeCovCountRibo:
	input:
		rules.collectCovCountRibo.output
	output:
		config["COVDIR"] +config["COMPAREBATCH"] + "/" +  "allribocov.wide" + ".txt.gz"
	threads: 1
	params:
		splitby = config["SPLITBY"], sampleinfo = config["SAMPLEINFO"]
	shell:
		"""
			Rscript {config[RESHAPETABLE]} -i {input} -o {output} -v V3 -f V1+V2~V4 --header F --filterbySum 0 --splitBy {params.splitby} --sampleinfo {params.sampleinfo}
		"""


rule qualityCheck:
	input:
		highcov = rules.reshapeCovCountHigh.output,
		sampleinfo = config["SAMPLEINFO"],
		trimlog = rules.collectAdpTrimLog.output,
		maplog = rules.collectMapLog.output,
	output:
		pwheatmap = config["QUALCHECKDIR"] + config["COMPAREBATCH"] + "/" + "pairwiseHeatmap.pdf",
		proSum = config["QUALCHECKDIR"] + config["COMPAREBATCH"] + "/" + "processingSummary.xls",
		proSumPlot = config["QUALCHECKDIR"] + config["COMPAREBATCH"] + "/" + "SummaryOfProcessing.pdf"
	params:
		outdir = config["QUALCHECKDIR"] + config["COMPAREBATCH"], batch = config["COMPAREBATCH"]
	shell:
		"""
			Rscript {config[QUALCHECKSCRIPT]} {input.highcov} {input.sampleinfo} {input.trimlog} {input.maplog} {params.batch} F 10 {params.outdir}
		"""
		
		
EVALUEPRE = RESULTDIR + "Site_{treatment}" + "_" + config["TOPCOV"]
EVALUEDIR = EVALUEPRE + "_{suffix}/"

rule calldiffsites:
	input:
		covfile = rules.reshapeCovCount.output 
	output: 
		pvaluefile = config["PARCELDIR"] + config["COMPAREBATCH"] + "/" + "etTable_{treatment}.Rdata"
	params:
		outdir = config["PARCELDIR"] + config["COMPAREBATCH"] + "/", mincov = config["COVMIN"], treatment = lambda wildcards: wildcards.treatment, sampleinfo = config["SAMPLEINFO"],
		sffile = config["PARCELDIR"] + config["COMPAREBATCH"] + "/" + "edgeR_sf.Rdata", batch = config["COMPAREBATCH"],control = config["CONTROL"], vsall = config["VSALL"],chrsize = config["GENOMESIZE"],downSampleProp = config["DOWNSAMPLEPROP"], ismerge = config["ISMERGE"], chrcov = config["CHRCOV"]

	threads: 4 
	shell:
		"""
			Rscript {config[RUNEDGER]} --args {params.outdir} {params.mincov} {params.treatment} {params.sampleinfo} {params.batch} {input.covfile} {params.sffile} {params.chrsize} {params.chrcov} {params.ismerge}
		"""

rule getCandidateRegions:
	input:
		pvaluefile = rules.calldiffsites.output.pvaluefile,
		covfile = rules.reshapeCovCount.output
	output:
		config["PARCELDIR"] + config["COMPAREBATCH"] + "/" + "fastq2_{treatment}_output10.Rdata"
	params:
		mincov = config["COVMIN"], treatment = lambda wildcards: wildcards.treatment, outdir = rules.calldiffsites.params.outdir,
		sffile = rules.calldiffsites.params.sffile
	shell:
		"""
			Rscript {config[REGIONEVALUE]} --args {params.treatment} {params.outdir}
		"""


rule filterCandidates:
	input:
		diffsitefile = rules.getCandidateRegions.output,
		covfile = rules.reshapeCovCount.output
	output:
		filtercands = config["PARCELDIR"] + config["COMPAREBATCH"] + "/" + "combined_{treatment}_output2_wfilters.txt",
	params:
		treatment = lambda wildcards: wildcards.treatment, outdir = rules.calldiffsites.params.outdir, exons = config["GENEEXONBED"],
		sffile = rules.calldiffsites.params.sffile, sampleinfo = config["SAMPLEINFO"], batch = config["COMPAREBATCH"], ismerge = config["ISMERGE"]
	shell:
		"""
			Rscript {config[FILTERCANDS]} --args {params.treatment} {params.outdir} {input.covfile} {params.sffile} {params.sampleinfo} {params.batch} {params.exons} {params.ismerge}
		"""

rule convertToGenome:
	input:
		rules.filterCandidates.output.filtercands
	output:
		candbed = config["PARCELDIR"] + config["COMPAREBATCH"] + "/" + "combined_{treatment}_output2_wfilters.bed",
		#candseq = temp(config["PARCELDIR"] + config["COMPAREBATCH"] + "/" + "combined_{treatment}_output2_wfilters.fa"),
	params:
		refTranscript = config["GENOMEFASTA"], refGenome = config["GENOMEFASTA"]
	shell:
		"""
			Rscript {config[CONVERTTOBED]} -i {input} -o {output.candbed} 
		"""
	
rule coveragePlot:
	input:
		filtercands = rules.convertToGenome.output.candbed,
		siterawcov = config["RAWCOV"]
		
	output:
		sigregion = config["PARCELDIR"] + config["COMPAREBATCH"] + "/{treatment}_covplot/sigRegion.xls",
		sequences = config["PARCELDIR"] + config["COMPAREBATCH"] + "/{treatment}_covplot/sequences.fas",
		ribocov = config["PARCELDIR"] + config["COMPAREBATCH"] + "/{treatment}_covplot/covinfo.xls"
		
	params:
		sampleinfo = config["SAMPLEINFO"], nrexonbed = config["GENEEXONBED"], treatment = lambda wildcards: wildcards.treatment, control = config["CONTROL"], 
		topcov = config["TOPCOV"], batch = config["COMPAREBATCH"], autobatch = config["AUTOBATCH"], genome = config["GENOMEFASTA"], cdsbed = config["CDSBED"],
		outdir = rules.filterCandidates.params.outdir + "{treatment}_covplot/", ismerge = config["ISMERGE"]
	threads: 16
	shell:
		"""
			Rscript {config[COVPLOT]} -o {params.outdir} -i {input.filtercands} -s {params.sampleinfo} -b {params.batch} -t {params.treatment} -c {params.control} --covfile {input.siterawcov} --genome {params.genome} --getFasta T --CDSBed {params.cdsbed} --genomeSize {config[GENOMESIZE]} --ismerge {params.ismerge}
		"""

